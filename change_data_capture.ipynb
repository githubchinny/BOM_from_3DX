{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "import platform\n",
    "import os\n",
    "import validate_bom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_folder_defaults():\n",
    "    if 'macOS' in platform.platform():\n",
    "        # set some defaults for testing on mac\n",
    "        download_dir = Path('/Users/mark/Downloads')\n",
    "        user_dir = download_dir\n",
    "        sharepoint_dir = download_dir\n",
    "\n",
    "    elif 'Server' in platform.platform():\n",
    "        # we're on the azure server (probably)\n",
    "        user_dir = Path('Z:/python/FilesIn')\n",
    "\n",
    "        download_dir = Path(user_dir)\n",
    "        user_dir = download_dir\n",
    "        sharepoint_dir = Path('Z:/python/FilesOut')\n",
    "\n",
    "    elif os.getlogin() == 'mark_':\n",
    "        # my test windows machine\n",
    "        download_dir = Path('C:/Users/mark_/Downloads')\n",
    "        user_dir = download_dir\n",
    "        sharepoint_dir = download_dir        \n",
    "\n",
    "    else:\n",
    "        # personal one drive\n",
    "        user_dir = 'C:/Users/USERNAME'\n",
    "\n",
    "        # replace USERNAME with current logged on user\n",
    "        user_dir = user_dir.replace('USERNAME', os.getlogin())\n",
    "\n",
    "        # read in config file\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('user_directory.ini')\n",
    "\n",
    "        # read in gm_dir and gm_docs from config file\n",
    "        gm_dir = Path(config[os.getlogin().lower()]['gm_dir'])\n",
    "        gm_docs = Path(config[os.getlogin().lower()]['gmt'])\n",
    "        # this may find more than one sharepoint directory\n",
    "        # sharepoint_dir = user_dir + \"/\" + gm_dir + \"/\" + gm_docs\n",
    "        sharepoint_dir = Path(user_dir / gm_dir / gm_docs)\n",
    "\n",
    "        # download_dir = os.path.join(sharepoint_dir, 'Data Shuttle', 'downloads')\n",
    "        download_dir = Path(sharepoint_dir / 'Data Shuttle' / 'downloads')\n",
    "\n",
    "    return sharepoint_dir, download_dir, user_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(download_dir, search='*'):\n",
    "    files = []\n",
    "    for file in Path(download_dir).glob(search):\n",
    "        print (file)\n",
    "        files.append(file)\n",
    " \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_xl(output_file, dict_checks):\n",
    "\n",
    "    outfile = output_file\n",
    "    df_dict = dict_checks\n",
    "\n",
    "    import xlwings as xw\n",
    "    try:\n",
    "        wb = xw.Book(output_file)\n",
    "        print (\"writing to existing {}\".format(outfile))\n",
    "    except FileNotFoundError:\n",
    "        # create a new book\n",
    "        print (\"creating new {}\".format(outfile))\n",
    "        wb = xw.Book()\n",
    "        # wb.save(outfile)\n",
    "\n",
    "    for key in df_dict.keys():\n",
    "        try:\n",
    "            ws = wb.sheets.add(key)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "        \n",
    "        ws = wb.sheets[key]\n",
    "\n",
    "        table_name = key\n",
    "\n",
    "        ws.clear()\n",
    "\n",
    "        df = df_dict[key]\n",
    "        if len(df) > 0:\n",
    "            if table_name in [table.df for table in ws.tables]:\n",
    "                ws.tables[table_name].update(df)\n",
    "            else:\n",
    "                table_name = ws.tables.add(source=ws['A1'],\n",
    "                                            name=table_name).update(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-04-15.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-04-19.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-05-22.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-05-23.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-05-24.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-05-28.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-05-30.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00001_2024-06-04.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48e-01-Z00003_2024-04-15.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-04-15.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-04-19.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-05-22.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-05-23.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-05-30.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-05-31.xlsx\n",
      "C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-06-04.xlsx\n",
      "Found 16 files for Updated*2024*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mark_\\Documents\\GitHub\\BOM_from_3DX\\validate_bom.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'AIH' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'Parent Source Code'] = level_source[x['Level'] - 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No variant lookup found for T48E-01-Z00003 Therefore didn't update variant name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mark_\\Documents\\GitHub\\BOM_from_3DX\\validate_bom.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'AIH' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'Parent Source Code'] = level_source[x['Level'] - 1]\n",
      "c:\\Users\\mark_\\Documents\\GitHub\\BOM_from_3DX\\validate_bom.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'AIH' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'Parent Source Code'] = level_source[x['Level'] - 1]\n"
     ]
    }
   ],
   "source": [
    "# this gets called if running from this script.  \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    sharepoint_dir, download_dir, user_dir = set_folder_defaults()\n",
    "    file_search = 'Updated*2024*'\n",
    "    files = find_files(Path(download_dir / 'T48E'), file_search)\n",
    "    print (\"Found {} files for {}\".format(len(files), file_search))\n",
    "    # reverse the sort order\n",
    "    files.sort(reverse=True)\n",
    "    # just take the last x files from the top, being the latest\n",
    "    # files = files[:5]\n",
    "    # resort from old at top to latest at bottom\n",
    "    files.sort(reverse=False)\n",
    "\n",
    "    dict_df = {}\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"rb\") as f:\n",
    "            filename = Path(file).stem\n",
    "            # reading in the historic excel files\n",
    "            df = pd.read_excel(f, parse_dates=True)\n",
    "            f.close()\n",
    "            # if percent_missing row is there get rid of it\n",
    "            df = df[df.orig_sort != 'percent_missing']\n",
    "            # format last export date as date only\n",
    "            df['Last Export Date'] = pd.to_datetime(df['Last Export Date']).dt.date\n",
    "            # store the export date from the first row (all the same)\n",
    "            last_export_date = df['Last Export Date'].head(1).values\n",
    "            # BOM COUNT is not needed \n",
    "            try:\n",
    "                df.drop(columns='BOM COUNT', inplace=True)\n",
    "            except KeyError:\n",
    "                # didn't find BOM COUNT - doesn't matter\n",
    "                pass\n",
    "            # take the Variant from the level 0 Title\n",
    "            variant = df.Title[df.Level == 0]\n",
    "            # drop packaging function group in case it's in the original extracts\n",
    "            df = df[~df['Function Group'].str.contains('PACKAGING', na=False)]\n",
    "            # add the latest validation metrics to our df\n",
    "            val_dict = validate_bom.main(df)\n",
    "            # the BOM dataframe will have what we're after\n",
    "            dict_df[filename] = val_dict['BOM']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_d = {}\n",
    "\n",
    "summary_d['xtab'] = pd.DataFrame()\n",
    "summary_d['xtab_norm'] = pd.DataFrame()\n",
    "\n",
    "for df in dict_df:\n",
    "    xtab = pd.crosstab([dict_df[df]['Last Export Date'], dict_df[df]['Variant'], dict_df[df]['Function Group']], dict_df[df]['Source Code'].fillna('Missing'))\n",
    "    summary_d['xtab'] = pd.concat([summary_d['xtab'],xtab])\n",
    "\n",
    "    xtab_norm = pd.crosstab([dict_df[df]['Last Export Date'], dict_df[df]['Variant'], dict_df[df]['Function Group']], dict_df[df]['Source Code'].fillna('Missing'), normalize='index')\n",
    "    summary_d['xtab_norm'] = pd.concat([summary_d['xtab_norm'], xtab_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['xtab', 'xtab_norm'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new summary_metrics\n"
     ]
    }
   ],
   "source": [
    "write_to_xl('summary_metrics', summary_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, figsize):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "       \n",
    "    hmap = plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(df, annot = True, fmt=\".0%\", cmap='YlGnBu', annot_kws={'fontsize':8}, linewidths=0.5)\n",
    "    ax.set(xlabel=\"\", ylabel=\"\")\n",
    "    ax.xaxis.tick_top()\n",
    "    plt.rc('xtick', labelsize=10)\n",
    "    plt.rc('ytick', labelsize=10)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, .2, .75, 1])\n",
    "    cbar.set_ticklabels(['0%', '20%', '75%', '100%'])\n",
    "    plt.figure()\n",
    "    # sns.set(font_scale=.5)\n",
    "    # plt.show()\n",
    "    plt.close(hmap)\n",
    "    return hmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'datetime.date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m create_heatmap(summary_d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpdated_T48e-01-Z00001_2024-04-15\u001b[39m\u001b[38;5;124m'\u001b[39m], (\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mcreate_heatmap\u001b[1;34m(df, figsize)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m hmap \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[1;32m----> 8\u001b[0m ax \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mheatmap(df, annot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.0\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYlGnBu\u001b[39m\u001b[38;5;124m'\u001b[39m, annot_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfontsize\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m8\u001b[39m}, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      9\u001b[0m ax\u001b[38;5;241m.\u001b[39mset(xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m ax\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mtick_top()\n",
      "File \u001b[1;32mc:\\Users\\mark_\\anaconda3\\envs\\python312\\Lib\\site-packages\\seaborn\\matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    447\u001b[0m                       annot_kws, cbar, cbar_kws, xticklabels,\n\u001b[0;32m    448\u001b[0m                       yticklabels, mask)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32mc:\\Users\\mark_\\anaconda3\\envs\\python312\\Lib\\site-packages\\seaborn\\matrix.py:163\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mylabel \u001b[38;5;241m=\u001b[39m ylabel \u001b[38;5;28;01mif\u001b[39;00m ylabel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Determine good default values for the colormapping\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0;32m    164\u001b[0m                             cmap, center, robust)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Sort out the annotations\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mark_\\anaconda3\\envs\\python312\\Lib\\site-packages\\seaborn\\matrix.py:197\u001b[0m, in \u001b[0;36m_HeatMapper._determine_cmap_params\u001b[1;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use some heuristics to set good defaults for colorbar and range.\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# plot_data is a np.ma.array instance\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m calc_data \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mfilled(np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vmin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m robust:\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'datetime.date'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_heatmap(summary_d['Updated_T48e-01-Z00001_2024-04-15'], (12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
